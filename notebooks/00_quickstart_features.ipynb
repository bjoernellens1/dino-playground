{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 00 Quickstart: DINOv3 Features\n",
                "\n",
                "This notebook demonstrates how to load the DINOv3 backbone and visualize features using PCA."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "from transformers import AutoImageProcessor\n",
                "from sklearn.decomposition import PCA\n",
                "\n",
                "from dinov3_lab.core.backbone import build_dinov3_hf\n",
                "\n",
                "# 1. Load Model\n",
                "model_id = \"facebook/dinov3-vitl16-pretrain-lvd1689m\"\n",
                "backbone = build_dinov3_hf(model_id=model_id)\n",
                "processor = AutoImageProcessor.from_pretrained(model_id)\n",
                "\n",
                "# 2. Load Image\n",
                "# Replace with your image path\n",
                "image_path = \"../data/test_images/demo.jpg\" \n",
                "# !wget https://github.com/pytorch/hub/raw/master/images/dog.jpg -O ../data/test_images/demo.jpg\n",
                "try:\n",
                "    image = Image.open(image_path).convert(\"RGB\")\n",
                "except FileNotFoundError:\n",
                "    print(\"Please download a demo image to ../data/test_images/demo.jpg\")\n",
                "    # Create a dummy image\n",
                "    image = Image.new('RGB', (448, 448), color = 'red')\n",
                "\n",
                "inputs = processor(images=image, return_tensors=\"pt\")\n",
                "\n",
                "# 3. Extract Features\n",
                "with torch.no_grad():\n",
                "    out = backbone(inputs.pixel_values)\n",
                "\n",
                "print(f\"CLS shape: {out.cls.shape}\")\n",
                "print(f\"Patch tokens shape: {out.patch_tokens.shape}\")\n",
                "\n",
                "# 4. Visualize PCA\n",
                "patch_tokens = out.patch_tokens[0].float().cpu().numpy()\n",
                "pca = PCA(n_components=3)\n",
                "pca_features = pca.fit_transform(patch_tokens)\n",
                "\n",
                "h, w = out.patch_hw\n",
                "pca_img = pca_features.reshape(h, w, 3)\n",
                "\n",
                "# Normalize to 0-1 for display\n",
                "pca_img = (pca_img - pca_img.min()) / (pca_img.max() - pca_img.min())\n",
                "\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.imshow(image)\n",
                "plt.title(\"Original Image\")\n",
                "plt.axis(\"off\")\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.imshow(pca_img)\n",
                "plt.title(\"PCA of Features\")\n",
                "plt.axis(\"off\")\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}