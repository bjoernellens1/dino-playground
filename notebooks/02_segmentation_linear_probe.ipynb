{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02 Linear Probe Segmentation\n",
                "\n",
                "Train a simple linear head on top of frozen DINOv3 features using ADE20K dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "from transformers import AutoImageProcessor\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "from dinov3_lab.core.backbone import build_dinov3_hf\n",
                "from dinov3_lab.tasks.segmentation.heads import LinearSegmentationHead\n",
                "from dinov3_lab.data.datasets.ade20k import ADE20KDataset\n",
                "\n",
                "# 1. Setup\n",
                "model_id = \"facebook/dinov3-vitl16-pretrain-lvd1689m\"\n",
                "backbone = build_dinov3_hf(model_id=model_id)\n",
                "head = LinearSegmentationHead(in_channels=1024, num_classes=150)\n",
                "processor = AutoImageProcessor.from_pretrained(model_id)\n",
                "\n",
                "# Freeze backbone\n",
                "for param in backbone.parameters():\n",
                "    param.requires_grad = False"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Dataset & Dataloader\n",
                "# NOTE: Update 'root' to point to your ADE20K dataset location\n",
                "data_root = \"../data/ade20k\"\n",
                "try:\n",
                "    dataset = ADE20KDataset(root=data_root, split=\"train\")\n",
                "    dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
                "    print(f\"Loaded ADE20K dataset with {len(dataset)} samples.\")\n",
                "except FileNotFoundError:\n",
                "    print(\"ADE20K dataset not found. Please download it or check the path.\")\n",
                "    # Fallback for demo purposes if needed, or just stop\n",
                "    dataset = None\n",
                "    dataloader = None\n",
                "\n",
                "if dataset:\n",
                "    # 3. Training Loop\n",
                "    optimizer = optim.AdamW(head.parameters(), lr=1e-3)\n",
                "    criterion = nn.CrossEntropyLoss(ignore_index=0) # Assuming 0 is background/ignore in ADE20K raw\n",
                "\n",
                "    print(\"Starting training...\")\n",
                "    head.train()\n",
                "    # Train for a few batches for demo\n",
                "    max_steps = 10\n",
                "    step = 0\n",
                "    \n",
                "    for epoch in range(1):\n",
                "        total_loss = 0\n",
                "        for images, masks in dataloader:\n",
                "            if step >= max_steps: break\n",
                "            \n",
                "            # Prepare inputs\n",
                "            inputs = processor(images=images, return_tensors=\"pt\")\n",
                "            \n",
                "            # Forward pass backbone (no grad)\n",
                "            with torch.no_grad():\n",
                "                out = backbone(inputs.pixel_values)\n",
                "                grid = backbone.tokens_to_grid(out.patch_tokens, out.patch_hw)\n",
                "            \n",
                "            # Forward pass head\n",
                "            logits = head(grid.float())\n",
                "            \n",
                "            # Upsample logits to mask size for loss computation\n",
                "            # Note: masks might need to be converted to tensor long if not done by collate\n",
                "            # Here we assume basic PIL -> Tensor conversion happened or we do it:\n",
                "            if not isinstance(masks, torch.Tensor):\n",
                "                 # Basic conversion if dataset returns PIL\n",
                "                 import numpy as np\n",
                "                 masks = torch.as_tensor(np.array(masks), dtype=torch.long)\n",
                "            \n",
                "            logits_up = nn.functional.interpolate(logits, size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
                "            \n",
                "            loss = criterion(logits_up, masks)\n",
                "            \n",
                "            # Backward\n",
                "            optimizer.zero_grad()\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            \n",
                "            total_loss += loss.item()\n",
                "            step += 1\n",
                "            print(f\"Step {step}, Loss: {loss.item():.4f}\")\n",
                "        \n",
                "        if step >= max_steps: break"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Evaluation / Visualization\n",
                "if dataset:\n",
                "    head.eval()\n",
                "    image, mask = dataset[0]\n",
                "    inputs = processor(images=image, return_tensors=\"pt\")\n",
                "\n",
                "    with torch.no_grad():\n",
                "        out = backbone(inputs.pixel_values)\n",
                "        grid = backbone.tokens_to_grid(out.patch_tokens, out.patch_hw)\n",
                "        logits = head(grid.float())\n",
                "        logits_up = nn.functional.interpolate(logits, size=mask.size[::-1], mode=\"bilinear\", align_corners=False)\n",
                "        pred_mask = logits_up.argmax(dim=1)[0]\n",
                "\n",
                "    plt.figure(figsize=(15, 5))\n",
                "    plt.subplot(1, 3, 1)\n",
                "    plt.imshow(image)\n",
                "    plt.title(\"Input\")\n",
                "    plt.axis(\"off\")\n",
                "\n",
                "    plt.subplot(1, 3, 2)\n",
                "    plt.imshow(mask)\n",
                "    plt.title(\"Ground Truth\")\n",
                "    plt.axis(\"off\")\n",
                "\n",
                "    plt.subplot(1, 3, 3)\n",
                "    plt.imshow(pred_mask.cpu().numpy())\n",
                "    plt.title(\"Prediction\")\n",
                "    plt.axis(\"off\")\n",
                "    plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}