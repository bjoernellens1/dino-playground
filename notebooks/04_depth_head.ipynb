{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 04 Depth Estimation\n",
                "\n",
                "Predict dense depth maps using DINOv3 features and ScanNet dataset with PyTorch Lightning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import pytorch_lightning as pl\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "from transformers import AutoImageProcessor\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "from dinov3_lab.core.backbone import build_dinov3_hf\n",
                "from dinov3_lab.tasks.depth.heads import DepthHead\n",
                "from dinov3_lab.data.datasets.scannet import ScanNetDataset\n",
                "\n",
                "# 1. Setup Lightning Module\n",
                "class DepthModule(pl.LightningModule):\n",
                "    def __init__(self, model_id):\n",
                "        super().__init__()\n",
                "        self.save_hyperparameters()\n",
                "        self.backbone = build_dinov3_hf(model_id=model_id)\n",
                "        self.head = DepthHead(in_channels=1024)\n",
                "        self.criterion = nn.MSELoss()\n",
                "        self.processor = AutoImageProcessor.from_pretrained(model_id)\n",
                "        \n",
                "        # Freeze backbone\n",
                "        for param in self.backbone.parameters():\n",
                "            param.requires_grad = False\n",
                "\n",
                "    def forward(self, pixel_values):\n",
                "        with torch.no_grad():\n",
                "            out = self.backbone(pixel_values)\n",
                "            grid = self.backbone.tokens_to_grid(out.patch_tokens, out.patch_hw)\n",
                "        return self.head(grid.float())\n",
                "\n",
                "    def training_step(self, batch, batch_idx):\n",
                "        images, depths = batch\n",
                "        # Preprocessing\n",
                "        inputs = self.processor(images=images, return_tensors=\"pt\")\n",
                "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
                "        \n",
                "        depth_pred = self(inputs['pixel_values'])\n",
                "        \n",
                "        # Upsample and normalize target\n",
                "        if not isinstance(depths, torch.Tensor):\n",
                "             import numpy as np\n",
                "             depths_np = np.array(depths, dtype=np.float32) / 1000.0\n",
                "             depths = torch.as_tensor(depths_np, device=self.device).unsqueeze(1)\n",
                "        else:\n",
                "             depths = depths.to(self.device).unsqueeze(1)\n",
                "        \n",
                "        depth_pred_up = nn.functional.interpolate(depth_pred, size=depths.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
                "        loss = self.criterion(depth_pred_up, depths)\n",
                "        self.log(\"train_loss\", loss, prog_bar=True)\n",
                "        return loss\n",
                "\n",
                "    def configure_optimizers(self):\n",
                "        return optim.AdamW(self.head.parameters(), lr=1e-3)\n",
                "\n",
                "model_id = \"facebook/dinov3-vitl16-pretrain-lvd1689m\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Dataset & Training\n",
                "data_root = \"../data/scannet\"\n",
                "try:\n",
                "    dataset = ScanNetDataset(root=data_root, split=\"train\")\n",
                "    dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
                "    print(f\"Loaded ScanNet dataset with {len(dataset)} samples.\")\n",
                "except FileNotFoundError:\n",
                "    print(\"ScanNet dataset not found.\")\n",
                "    dataset = None\n",
                "    dataloader = None\n",
                "\n",
                "if dataset:\n",
                "    module = DepthModule(model_id=model_id)\n",
                "    \n",
                "    trainer = pl.Trainer(\n",
                "        max_epochs=1,\n",
                "        limit_train_batches=10,\n",
                "        accelerator=\"gpu\",\n",
                "        devices=1,\n",
                "        precision=\"bf16-mixed\"\n",
                "    )\n",
                "    \n",
                "    trainer.fit(module, dataloader)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Evaluation / Visualization\n",
                "if dataset:\n",
                "    module.eval()\n",
                "    module.cuda()\n",
                "    image, depth_gt = dataset[0]\n",
                "    inputs = module.processor(images=image, return_tensors=\"pt\")\n",
                "    inputs = {k: v.to(module.device) for k, v in inputs.items()}\n",
                "\n",
                "    with torch.no_grad():\n",
                "        depth_pred = module(inputs['pixel_values'])\n",
                "        depth_pred_up = nn.functional.interpolate(depth_pred, size=image.size[::-1], mode=\"bilinear\", align_corners=False)\n",
                "\n",
                "    plt.figure(figsize=(15, 5))\n",
                "    plt.subplot(1, 3, 1)\n",
                "    plt.imshow(image)\n",
                "    plt.title(\"Input\")\n",
                "    plt.axis(\"off\")\n",
                "\n",
                "    plt.subplot(1, 3, 2)\n",
                "    plt.imshow(depth_gt, cmap=\"plasma\")\n",
                "    plt.title(\"Ground Truth Depth\")\n",
                "    plt.axis(\"off\")\n",
                "\n",
                "    plt.subplot(1, 3, 3)\n",
                "    plt.imshow(depth_pred_up[0, 0].cpu().numpy(), cmap=\"plasma\")\n",
                "    plt.title(\"Predicted Depth\")\n",
                "    plt.axis(\"off\")\n",
                "    plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}